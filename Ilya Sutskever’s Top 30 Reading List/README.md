- **The Annotated Transformer.** Sasha Rush, et al. [[Blog]](https://nlp.seas.harvard.edu/annotated-transformer/) [[Code]](https://github.com/harvardnlp/annotated-transformer/)
- **The First Law of Complexodynamics.** Scott Aaronson. [[Blog]](https://scottaaronson.blog/?p=762)
- **The Unreasonable Effectiveness of Recurrent Neural Networks.** Andrej Karpathy. [[Blog]](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) [[Code]](https://github.com/karpathy/char-rnn)
- **Understanding LSTM Networks.** Christopher Olah. [[Blog]](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- **Recurrent Neural Network Regularization.** Wojciech Zaremba, et al. [[ArXiv]](https://arxiv.org/abs/1409.2329) [[pdf]](https://arxiv.org/pdf/1409.2329) [[Code]](https://github.com/wojzaremba/lstm)
- **Keeping Neural Networks Simple by Minimizing the Description Length of the Weights.** Geoffrey E. Hinton and Drew van Camp. [[Paper]](https://dl.acm.org/doi/10.1145/168304.168306) [[pdf]](https://www.cs.toronto.edu/~hinton/absps/colt93.pdf)
- **Pointer Networks.** Oriol Vinyals, et al. [[Paper]](https://papers.nips.cc/paper/5866-pointer-networks) [[pdf]](https://arxiv.org/pdf/1506.03134)
- **ImageNet Classification with Deep Convolutional Neural Networks.** Alex Krizhevsky, et al. [[Paper]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks) [[pdf]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
- **Order Matters: Sequence to sequence for sets.** Oriol Vinyals, et al. [[ArXiv]](https://arxiv.org/abs/1511.06391) [[pdf]](https://arxiv.org/pdf/1511.06391)
- **GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism.** Yanping Huang, et al. [[ArXiv]](https://arxiv.org/abs/1811.06965) [[pdf]](https://arxiv.org/pdf/1811.06965)
- **Deep Residual Learning for Image Recognition.** Kaiming He, et al.   [[Paper]](https://arxiv.org/pdf/1512.03385)
- **Multi-Scale Context Aggregation by Dilated Convolutions.** Fisher Yu and Vladlen Koltun. [[Paper]](https://arxiv.org/pdf/1511.07122)
- **Neural Message Passing for Quantum Chemistry.** Justin Gilmer, et al. [[Paper]](https://arxiv.org/pdf/1704.01212)
- **Attention Is All You Need.** Ashish Vaswani, et al. [[Paper]](https://arxiv.org/pdf/1706.03762)
- **Neural Machine Translation by Jointly Learning to Align and Translate.** Dzmitry Bahdanau, et al. [[Paper]](https://arxiv.org/pdf/1409.0473)
- **Identity Mappings in Deep Residual Networks.** Kaiming He, et al. [[Paper](https://arxiv.org/pdf/1603.05027)
- **A simple neural network module for relational reasoning.** Adam Santoro, et al. [[Paper]](https://arxiv.org/pdf/1706.01427)
- **Variational Lossy Autoencoder.** Xi Chen, et al. [[Paper]](https://arxiv.org/pdf/1611.02731)
- **Relational recurrent neural networks.** Adam Santoro, et al. [[Paper]](https://arxiv.org/pdf/1806.01822)
- **Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton.** Scott Aaronson, et al. [[Paper]](https://arxiv.org/pdf/1405.6903)
- **Neural Turing Machines.** Alex Graves, et al. [[Paper]](https://arxiv.org/pdf/1410.5401)
- **Deep Speech 2: End-to-End Speech Recognition in English and Mandarin.** Dario Amodei, et al. [[Paper](https://arxiv.org/pdf/1512.02595)
- **Scaling Laws for Neural Language Models.** Jared Kaplan, et al. [[Paper]](https://arxiv.org/pdf/2001.08361)
- **A Tutorial Introduction to the Minimum Description Length Principle.** Peter Grunwald. [[Paper]](https://arxiv.org/pdf/math/0406077)
- **Machine Super Intelligence.** Shane Legg. [[Paper]](https://www.vetta.org/documents/Machine_Super_Intelligence.pdf) 
- **Kolmogorov Complexity and Algorithmic Randomness.** A.Shen, V. A. Uspensky, and N. Vereshchagin. [[Paper]](https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf)
- **CS231n: Convolutional Neural Networks for Visual Recognition.** [[Paper]](https://cs231n.github.io/)
