{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T06:21:47.522232Z",
     "iopub.status.busy": "2023-10-26T06:21:47.521857Z",
     "iopub.status.idle": "2023-10-26T06:22:36.686850Z",
     "shell.execute_reply": "2023-10-26T06:22:36.685723Z",
     "shell.execute_reply.started": "2023-10-26T06:21:47.522200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain openai tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T06:22:36.688904Z",
     "iopub.status.busy": "2023-10-26T06:22:36.688579Z",
     "iopub.status.idle": "2023-10-26T06:22:36.696329Z",
     "shell.execute_reply": "2023-10-26T06:22:36.694591Z",
     "shell.execute_reply.started": "2023-10-26T06:22:36.688876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Enter your api key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Loaders\n",
    "### 1- Yükleyiciler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T07:24:05.589730Z",
     "iopub.status.busy": "2023-10-25T07:24:05.589289Z",
     "iopub.status.idle": "2023-10-25T07:24:16.582335Z",
     "shell.execute_reply": "2023-10-25T07:24:16.581090Z",
     "shell.execute_reply.started": "2023-10-25T07:24:05.589695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/kaggle/input/cs224u-contextreps/cs224u-contextualreps-2023-handout.pdf\")\n",
    "pages = loader.load()\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T07:27:29.626286Z",
     "iopub.status.busy": "2023-10-25T07:27:29.625752Z",
     "iopub.status.idle": "2023-10-25T07:27:29.633768Z",
     "shell.execute_reply": "2023-10-25T07:27:29.632439Z",
     "shell.execute_reply.started": "2023-10-25T07:27:29.626244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "page = pages[0]\n",
    "print(page.page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T07:25:38.453248Z",
     "iopub.status.busy": "2023-10-25T07:25:38.452734Z",
     "iopub.status.idle": "2023-10-25T07:25:38.462077Z",
     "shell.execute_reply": "2023-10-25T07:25:38.460477Z",
     "shell.execute_reply.started": "2023-10-25T07:25:38.453207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Document Splitting\n",
    "### 2- Belge Bölme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 20,\n",
    "    chunk_overlap = 5\n",
    ")\n",
    "\n",
    "character_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 20,\n",
    "    chunk_overlap = 5,\n",
    ")\n",
    "\n",
    "text = \"My name is Ahmed Eldokmak, nice to meet you\"\n",
    "\n",
    "recursive_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:01:40.645469Z",
     "iopub.status.busy": "2023-10-25T08:01:40.644993Z",
     "iopub.status.idle": "2023-10-25T08:01:40.653576Z",
     "shell.execute_reply": "2023-10-25T08:01:40.652292Z",
     "shell.execute_reply.started": "2023-10-25T08:01:40.645435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "character_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:02:03.331043Z",
     "iopub.status.busy": "2023-10-25T08:02:03.330536Z",
     "iopub.status.idle": "2023-10-25T08:02:03.340746Z",
     "shell.execute_reply": "2023-10-25T08:02:03.339322Z",
     "shell.execute_reply.started": "2023-10-25T08:02:03.330983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "character_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 20,\n",
    "    chunk_overlap = 5,\n",
    "    separator = ' '\n",
    ")\n",
    "\n",
    "character_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following example from (langchain chat with your data) short course from deeplearning.ai\n",
    "\n",
    "#### Deeplearning.ai'den (verilerinizle langchain sohbeti) kısa kursundan aşağıdaki örnek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:03:02.801451Z",
     "iopub.status.busy": "2023-10-25T08:03:02.800059Z",
     "iopub.status.idle": "2023-10-25T08:03:02.808683Z",
     "shell.execute_reply": "2023-10-25T08:03:02.807459Z",
     "shell.execute_reply.started": "2023-10-25T08:03:02.801395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:03:09.365474Z",
     "iopub.status.busy": "2023-10-25T08:03:09.365085Z",
     "iopub.status.idle": "2023-10-25T08:03:09.374987Z",
     "shell.execute_reply": "2023-10-25T08:03:09.373578Z",
     "shell.execute_reply.started": "2023-10-25T08:03:09.365444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:06:42.715482Z",
     "iopub.status.busy": "2023-10-25T08:06:42.714093Z",
     "iopub.status.idle": "2023-10-25T08:06:42.724223Z",
     "shell.execute_reply": "2023-10-25T08:06:42.722306Z",
     "shell.execute_reply.started": "2023-10-25T08:06:42.715434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:06:50.132236Z",
     "iopub.status.busy": "2023-10-25T08:06:50.131729Z",
     "iopub.status.idle": "2023-10-25T08:06:50.141950Z",
     "shell.execute_reply": "2023-10-25T08:06:50.140805Z",
     "shell.execute_reply.started": "2023-10-25T08:06:50.132198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading + splitting our own data\n",
    "### Kendi verilerimizi yükleme + bölme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:12:10.292215Z",
     "iopub.status.busy": "2023-10-25T08:12:10.291790Z",
     "iopub.status.idle": "2023-10-25T08:12:20.725916Z",
     "shell.execute_reply": "2023-10-25T08:12:20.724637Z",
     "shell.execute_reply.started": "2023-10-25T08:12:10.292180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"/kaggle/input/cs224u-contextreps/cs224u-contextualreps-2023-handout.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 150,\n",
    "    length_function = len,\n",
    "    separator = \"\\n\"\n",
    ")\n",
    "docs = splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:12:26.821247Z",
     "iopub.status.busy": "2023-10-25T08:12:26.820828Z",
     "iopub.status.idle": "2023-10-25T08:12:26.827497Z",
     "shell.execute_reply": "2023-10-25T08:12:26.826570Z",
     "shell.execute_reply.started": "2023-10-25T08:12:26.821215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:12:32.102232Z",
     "iopub.status.busy": "2023-10-25T08:12:32.101804Z",
     "iopub.status.idle": "2023-10-25T08:12:32.110615Z",
     "shell.execute_reply": "2023-10-25T08:12:32.109228Z",
     "shell.execute_reply.started": "2023-10-25T08:12:32.102199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:19:20.710663Z",
     "iopub.status.busy": "2023-10-25T08:19:20.710214Z",
     "iopub.status.idle": "2023-10-25T08:19:20.719404Z",
     "shell.execute_reply": "2023-10-25T08:19:20.717923Z",
     "shell.execute_reply.started": "2023-10-25T08:19:20.710594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:20:58.893276Z",
     "iopub.status.busy": "2023-10-25T08:20:58.892505Z",
     "iopub.status.idle": "2023-10-25T08:20:58.900941Z",
     "shell.execute_reply": "2023-10-25T08:20:58.899386Z",
     "shell.execute_reply.started": "2023-10-25T08:20:58.893235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:19:26.524935Z",
     "iopub.status.busy": "2023-10-25T08:19:26.524543Z",
     "iopub.status.idle": "2023-10-25T08:19:26.533950Z",
     "shell.execute_reply": "2023-10-25T08:19:26.532568Z",
     "shell.execute_reply.started": "2023-10-25T08:19:26.524905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "docs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:23:18.151826Z",
     "iopub.status.busy": "2023-10-25T08:23:18.151184Z",
     "iopub.status.idle": "2023-10-25T08:23:20.503044Z",
     "shell.execute_reply": "2023-10-25T08:23:20.501611Z",
     "shell.execute_reply.started": "2023-10-25T08:23:18.151779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=1, \n",
    "    chunk_overlap=0\n",
    ")\n",
    "text1 = \"fasd fdas err\"\n",
    "\n",
    "splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EN\n",
    "### Context Aware splitting\n",
    "#### The following example is also from (langchain chat with your data) short course from deeplearning.ai\n",
    "\n",
    "##### TR\n",
    "### Bağlama Duyarlı bölme\n",
    "#### Aşağıdaki örnek de deeplearning.ai'deki (verilerinizle langchain chat) kısa kursundan alınmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:25:38.878106Z",
     "iopub.status.busy": "2023-10-25T08:25:38.877576Z",
     "iopub.status.idle": "2023-10-25T08:25:38.886375Z",
     "shell.execute_reply": "2023-10-25T08:25:38.884962Z",
     "shell.execute_reply.started": "2023-10-25T08:25:38.878070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on = headers_to_split_on\n",
    ")\n",
    "\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T08:25:42.680605Z",
     "iopub.status.busy": "2023-10-25T08:25:42.680201Z",
     "iopub.status.idle": "2023-10-25T08:25:42.688673Z",
     "shell.execute_reply": "2023-10-25T08:25:42.687349Z",
     "shell.execute_reply.started": "2023-10-25T08:25:42.680574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Text Embedding\n",
    "### 3- Metin Gömme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-10-26T04:20:41.799616Z",
     "iopub.status.busy": "2023-10-26T04:20:41.799280Z",
     "iopub.status.idle": "2023-10-26T04:20:42.020291Z",
     "shell.execute_reply": "2023-10-26T04:20:42.018883Z",
     "shell.execute_reply.started": "2023-10-26T04:20:41.799590Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "sentence = \"My name is Ahmed Eldokmak, nice to meet you\"\n",
    "\n",
    "embedding1 = embedding.embed_query(sentence)\n",
    "embedding1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings convert text into vectors with meaning of each word\n",
    "\n",
    "yerleştirmeler, metni her kelimenin anlamını içeren vektörlere dönüştürür"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T04:31:00.325237Z",
     "iopub.status.busy": "2023-10-26T04:31:00.324857Z",
     "iopub.status.idle": "2023-10-26T04:31:00.988276Z",
     "shell.execute_reply": "2023-10-26T04:31:00.987388Z",
     "shell.execute_reply.started": "2023-10-26T04:31:00.325207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentence1 = \"I like NLP\"\n",
    "sentence2 = \"I like machine learning\"\n",
    "sentence3 = \"I hate lying\"\n",
    "\n",
    "# notice that sentence 1 and 2 have some similarities / 1. ve 2. cümlenin bazı benzerliklere sahip olduğuna dikkat edin \n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)\n",
    "\n",
    "result1 = np.dot(embedding1, embedding2)\n",
    "result2 = np.dot(embedding2, embedding3)\n",
    "\n",
    "print(f\"dot product of sentence1 and sentence2 = {result1}\\ndot product of sentence2 and sentence3 = {result2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Vector stores + Similarity search\n",
    "### 4- Vektör mağazaları + Benzerlik araması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import chromadb\n",
    "\n",
    "db = chromadb.from_documents(documents, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the name of lecturer?\"\n",
    "docs = db.similarity_search(question, k=3) # returns 3 relevant docs / 3 ilgili dokümanı döndürür"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Retrieval\n",
    "### 5- Geri Alma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T06:53:38.334534Z",
     "iopub.status.busy": "2023-10-26T06:53:38.334183Z",
     "iopub.status.idle": "2023-10-26T06:53:38.688936Z",
     "shell.execute_reply": "2023-10-26T06:53:38.687904Z",
     "shell.execute_reply.started": "2023-10-26T06:53:38.334511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "persist_directory = \"/kaggle/working/\"\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory = persist_directory,\n",
    "    embedding_function = embedding\n",
    ")\n",
    "\n",
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]\n",
    "\n",
    "db = Chroma.from_texts(\n",
    "    texts,\n",
    "    embedding = embedding\n",
    ")\n",
    "\n",
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EN\n",
    "### Accessing the data in the vector store\n",
    "#### 1- similarity search\n",
    "\n",
    "##### TR\n",
    "### Vektör deposundaki verilere erişme\n",
    "#### 1- benzerlik araması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T06:25:33.959696Z",
     "iopub.status.busy": "2023-10-26T06:25:33.959303Z",
     "iopub.status.idle": "2023-10-26T06:25:34.174378Z",
     "shell.execute_reply": "2023-10-26T06:25:34.172812Z",
     "shell.execute_reply.started": "2023-10-26T06:25:33.959668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "db.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Maximum marginal relevance\n",
    "#### 2- Maksimum marjinal alaka düzeyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T06:26:11.308554Z",
     "iopub.status.busy": "2023-10-26T06:26:11.308241Z",
     "iopub.status.idle": "2023-10-26T06:26:11.556687Z",
     "shell.execute_reply": "2023-10-26T06:26:11.555327Z",
     "shell.execute_reply.started": "2023-10-26T06:26:11.308532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "db.max_marginal_relevance_search(question, fetch_k= 3, k= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- metadata\n",
    "#### 3- meta veriler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "   question,\n",
    "   k=3,\n",
    "   filter={\"source\":\"Enter meta data\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM aided\n",
    "#### SelfQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This exmaple is from langchain chat with your data by deeplearning.ai / Bu örnek, deeplearning.ai tarafından verilerinizle yapılan langchain sohbetinden alınmıştır.\n",
    "# This cell is for explanation You can't run on your machine because you don't have a database / Bu hücre açıklama amaçlıdır. Veritabanınız olmadığı için makinenizde çalıştıramazsınız. \n",
    "# As a solution u can create your own database as explained in vector store section. / Çözüm olarak vektör mağazası bölümünde açıklandığı gibi kendi veritabanınızı oluşturabilirsiniz.\n",
    "\n",
    "from langchian.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]\n",
    "     \n",
    "\n",
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression\n",
    "## Sıkıştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
