{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a083ec73-85df-499a-859b-bafd75750f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 14:20:16.941672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747225216.954873 3637142 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747225216.958781 3637142 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-14 14:20:16.973911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/neuralnine/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/neuralnine/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, default_data_collator\n",
    "\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b26ce20-01d2-4cd7-81e9-bc0f9d597379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neuralnine/.local/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'TinyLLama/TinyLlama-1.1B-Chat-v1.0'\n",
    "adapter_path = './tinyllama-lora-tuned-adapter-math'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ").eval()\n",
    "\n",
    "tmp_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    "    trust_remote_code = True\n",
    ")\n",
    "\n",
    "tuned_model = PeftModel.from_pretrained(tmp_model, adapter_path)\n",
    "tuned_model = tuned_model.merge_and_unload().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5de189b-b646-4ab1-a9b1-071c5fbde753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    texts = [\n",
    "        f\"### Instruction:\\n{inst}\\n### Response:\\n{out}\"\n",
    "        for inst, out in zip(batch['question'], batch['answer'])\n",
    "    ]\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        padding = 'max_length',\n",
    "        truncation = True,\n",
    "        max_length = 256,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "    tokens['labels'] = tokens['input_ids'].clone()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36d1857-2bbf-4ad9-ba90-9b1020741693",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = load_dataset('openai/gsm8k', 'main', split='train[:20]')\n",
    "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['question', 'answer'])\n",
    "eval_ds = eval_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b989757-64f9-4614-bf38-6839e03c8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size = 8,\n",
    "    collate_fn = default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e0607d-a7c7-4bca-833f-dacaa2adf5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_perplexity(model):\n",
    "    losses = []\n",
    "    \n",
    "    for batch in eval_loader:\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        loss = model(**batch).loss\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return math.exp(sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e4511d-7315-4feb-870d-901995b9008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Perplexity: 139.69\n",
      "Tuned Model Perplexity: 1.04\n"
     ]
    }
   ],
   "source": [
    "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
    "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cddbaa73-1535-41df-a5b4-287fa2a65724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "raw_data = load_dataset('gsm8k', 'main', split='train[:20]')\n",
    "refs = raw_data['answer']\n",
    "\n",
    "\n",
    "def generate(model, instruction):\n",
    "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(token_ids, max_new_tokens=256)\n",
    "\n",
    "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c93c48-0957-49f5-8a18-7bd3e99fe530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['question'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02a3045-7ed1-423d-8df3-c32c48c09584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "### Response:\n",
      "The answer is $60.\n"
     ]
    }
   ],
   "source": [
    "print(generate(base_model, raw_data['question'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1169eb84-9bd6-4542-af66-7a5dcf72f4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "### Response:\n",
      "Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\n",
      "Working 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\n",
      "#### 10\n"
     ]
    }
   ],
   "source": [
    "print(generate(tuned_model, raw_data['question'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739ada9f-27f0-4f7b-bd10-17c2862894a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weng earns 12/60 = $<<12/60=0.2>>0.2 per minute.\n",
      "Working 50 minutes, she earned 0.2 x 50 = $<<0.2*50=10>>10.\n",
      "#### 10\n"
     ]
    }
   ],
   "source": [
    "print(refs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e51fa-aba0-4c26-ac05-907b6803ae8a",
   "metadata": {},
   "source": [
    "### Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "724d8049-77f7-4fe3-81b8-7ae230049786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603142204acb45c89bbfa3f123d086db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ds = load_dataset('openai/gsm8k', 'main', split='train[200:300]')\n",
    "eval_ds = eval_ds.map(tokenize, batched=True, remove_columns=['question', 'answer'])\n",
    "eval_ds = eval_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "377f2644-1907-40d1-8ab9-9deeb43a3b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size = 8,\n",
    "    collate_fn = default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f7de3c3-0022-41c1-98fe-7c0b09f683aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Perplexity: 229.85\n",
      "Tuned Model Perplexity: 7.63\n"
     ]
    }
   ],
   "source": [
    "print(f'Base Model Perplexity: {compute_perplexity(base_model):.2f}')\n",
    "print(f'Tuned Model Perplexity: {compute_perplexity(tuned_model):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9829ec42-8be1-4da8-9917-582428212e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_dataset('gsm8k', 'main', split='train[200:300]')\n",
    "refs = raw_data['answer']\n",
    "\n",
    "\n",
    "def generate(model, instruction):\n",
    "    token_ids = tokenizer(f'### Instruction:\\n{instruction}\\n### Response:\\n', return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(token_ids, max_new_tokens=256)\n",
    "\n",
    "    #return tokenizer.decode(out[0], skip_special_tokens=True).split('### Response:\\n')[-1].strip()\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5de7df0-040b-4e51-9469-affe4a7e7f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b359d50b-5952-4556-a220-ab8b2b87da1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Sansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?\n",
      "### Response:\n",
      "Sansa earns $100 per day, which means she earns $300 per week, and $1,200 per month, and $5,000 per year.\n"
     ]
    }
   ],
   "source": [
    "print(generate(base_model, raw_data['question'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c807032-b397-46cb-bbb4-5a63ad4bb214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Sansa is a famous artist, she can draw a portrait and sell it according to its size. She sells an 8-inch portrait for $5, and a 16-inch portrait for twice the price of the 8-inch portrait. If she sells three 8-inch portraits and five 16-inch portraits per day, how many does she earns every 3 days?\n",
      "### Response:\n",
      "Sansa earns an 8-inch portrait each and a 16-inch portrait each day for each day she sells it, respectively.\n",
      "So she earns an 8-inch portrait each day for 5 days a week and a 16-inch portrait each day for 2 days a week.\n",
      "The sum of the prices of the portraits they sell is $31 for 3 portraits per day.\n",
      "The number of portraits she sells in 3 days is $31/$8 = 3 portraits\n",
      "The number of portraits she sells in 2 days is $31/$16 = 3 portraits\n",
      "She earns an average of $12/portrait per day.\n",
      "#### 12\n"
     ]
    }
   ],
   "source": [
    "print(generate(tuned_model, raw_data['question'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "458a55e1-d93b-4ac1-a561-4284d4b94a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sansa earns $5 x 3 = $<<5*3=15>>15 every day by selling three 8-inch portraits.\n",
      "The price of the 16-inch portrait is $5 x 2 = $<<5*2=10>>10 each.\n",
      "So, she earns $10 x 5 = $<<10*5=50>>50 every day by selling five 16-inch portraits.\n",
      "Her total earnings is $50 + $15 = $<<50+15=65>>65 every day.\n",
      "Therefore, the total amount she earns after 3 days is $65 x 3 = $<<65*3=195>>195.\n",
      "#### 195\n"
     ]
    }
   ],
   "source": [
    "print(refs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aae4fd-8bd4-4bdb-b2bb-b96476f3a7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
